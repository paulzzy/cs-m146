{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZQ57FP3Zdq19"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PyqBmQZE7Uqw"
   },
   "outputs": [],
   "source": [
    "# To add your own Drive Run this cell.\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q4RwWjtN2sf4"
   },
   "outputs": [],
   "source": [
    "######################################################################\n",
    "# OneLayerNetwork\n",
    "######################################################################\n",
    "\n",
    "\n",
    "class OneLayerNetwork(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OneLayerNetwork, self).__init__()\n",
    "\n",
    "        ### ========== TODO : START ========== ###\n",
    "        ### part d: implement OneLayerNetwork with torch.nn.Linear\n",
    "\n",
    "        ### ========== TODO : END ========== ###\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x.shape = (n_batch, n_features)\n",
    "\n",
    "        ### ========== TODO : START ========== ###\n",
    "        ### part d: implement the foward function\n",
    "\n",
    "        ### ========== TODO : END ========== ###\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JRbW6WPv25tE"
   },
   "outputs": [],
   "source": [
    "######################################################################\n",
    "# TwoLayerNetwork\n",
    "######################################################################\n",
    "\n",
    "\n",
    "class TwoLayerNetwork(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TwoLayerNetwork, self).__init__()\n",
    "        ### ========== TODO : START ========== ###\n",
    "        ### part g: implement TwoLayerNetwork with torch.nn.Linear\n",
    "\n",
    "        ### ========== TODO : END ========== ###\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x.shape = (n_batch, n_features)\n",
    "\n",
    "        ### ========== TODO : START ========== ###\n",
    "        ### part g: implement the foward function\n",
    "\n",
    "        ### ========== TODO : END ========== ###\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I06zHwgTeSs3"
   },
   "outputs": [],
   "source": [
    "# load data from csv\n",
    "# X.shape = (n_examples, n_features), y.shape = (n_examples, )\n",
    "def load_data(filename):\n",
    "    data = np.loadtxt(filename)\n",
    "    y = data[:, 0].astype(int)\n",
    "    X = data[:, 1:].astype(np.float32) / 255\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JvP1DJfteUOn"
   },
   "outputs": [],
   "source": [
    "# plot one example\n",
    "# x.shape = (features, )\n",
    "def plot_img(x):\n",
    "    x = x.reshape(28, 28)\n",
    "    img = Image.fromarray(x * 255)\n",
    "    plt.figure()\n",
    "    plt.imshow(img)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RqaCgw9Z4Eef"
   },
   "outputs": [],
   "source": [
    "def evaluate_loss(model, criterion, dataloader):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    for batch_X, batch_y in dataloader:\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uEnwn4sC4F3B"
   },
   "outputs": [],
   "source": [
    "def evaluate_acc(model, dataloader):\n",
    "    model.eval()\n",
    "    total_acc = 0.0\n",
    "    for batch_X, batch_y in dataloader:\n",
    "        outputs = model(batch_X)\n",
    "        predictions = torch.argmax(outputs, dim=1)\n",
    "        total_acc += (predictions == batch_y).sum()\n",
    "\n",
    "    return total_acc / len(dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6OpXc_t7Jc5_"
   },
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, train_loader, valid_loader, epochs=31):\n",
    "    train_loss_list = []\n",
    "    valid_loss_list = []\n",
    "    train_acc_list = []\n",
    "    valid_acc_list = []\n",
    "    for epoch in range(1, epochs):\n",
    "        model.train()\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            pass\n",
    "            ### ========== TODO : START ========== ###\n",
    "            ### part f: implement the training process\n",
    "\n",
    "            ### ========== TODO : END ========== ###\n",
    "\n",
    "        train_loss = evaluate_loss(model, criterion, train_loader)\n",
    "        valid_loss = evaluate_loss(model, criterion, valid_loader)\n",
    "        train_acc = evaluate_acc(model, train_loader)\n",
    "        valid_acc = evaluate_acc(model, valid_loader)\n",
    "        train_loss_list.append(train_loss)\n",
    "        valid_loss_list.append(valid_loss)\n",
    "        train_acc_list.append(train_acc)\n",
    "        valid_acc_list.append(valid_acc)\n",
    "\n",
    "        print(\n",
    "            f\"| epoch {epoch:2d} | train loss {train_loss:.6f} | train acc {train_acc:.6f} | valid loss {valid_loss:.6f} | valid acc {valid_acc:.6f} |\"\n",
    "        )\n",
    "\n",
    "    return train_loss_list, valid_loss_list, train_acc_list, valid_acc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KMmurb4-d39G"
   },
   "outputs": [],
   "source": [
    "######################################################################\n",
    "# main\n",
    "######################################################################\n",
    "\n",
    "# def main():\n",
    "\n",
    "# fix random seed\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# load data with correct file path\n",
    "\n",
    "### ========== TODO : START ========== ###\n",
    "data_directory_path = \"/content/drive/My Drive/cm146/pset3\"\n",
    "### ========== TODO : END ========== ###\n",
    "\n",
    "# X.shape = (n_examples, n_features)\n",
    "# y.shape = (n_examples, )\n",
    "X_train, y_train = load_data(os.path.join(data_directory_path, \"ps3_train.csv\"))\n",
    "X_valid, y_valid = load_data(os.path.join(data_directory_path, \"ps3_valid.csv\"))\n",
    "X_test, y_test = load_data(os.path.join(data_directory_path, \"ps3_test.csv\"))\n",
    "\n",
    "### ========== TODO : START ========== ###\n",
    "### part a: print out three training images with different labels\n",
    "\n",
    "\n",
    "### ========== TODO : END ========== ###\n",
    "\n",
    "print(\"Data preparation...\")\n",
    "print(X_train.shape, X_test.shape)\n",
    "\n",
    "### ========== TODO : START ========== ###\n",
    "### part b: convert numpy arrays to tensors\n",
    "\n",
    "\n",
    "### ========== TODO : END ========== ###\n",
    "\n",
    "### ========== TODO : START ========== ###\n",
    "### part c: prepare dataloaders for training, validation, and testing\n",
    "###         we expect to get a batch of pairs (x_n, y_n) from the dataloader\n",
    "### train_loader = ...\n",
    "### valid_loader = ...\n",
    "### test_loader = ...\n",
    "\n",
    "\n",
    "### ========== TODO : END ========== ###\n",
    "\n",
    "### ========== TODO : START ========== ###\n",
    "### part e: prepare OneLayerNetwork, criterion, and optimizer\n",
    "\n",
    "\n",
    "### ========== TODO : END ========== ###\n",
    "\n",
    "print(\"Start training OneLayerNetwork...\")\n",
    "results_one = train(\n",
    "    model_one, criterion, optimizer, train_loader, valid_loader, epochs=31\n",
    ")\n",
    "print(\"Done!\")\n",
    "\n",
    "### ========== TODO : START ========== ###\n",
    "### part h: prepare TwoLayerNetwork, criterion, and optimizer\n",
    "\n",
    "\n",
    "### ========== TODO : END ========== ###\n",
    "\n",
    "print(\"Start training TwoLayerNetwork...\")\n",
    "results_two = train(\n",
    "    model_two, criterion, optimizer, train_loader, valid_loader, epochs=31\n",
    ")\n",
    "print(\"Done!\")\n",
    "\n",
    "one_train_loss, one_valid_loss, one_train_acc, one_valid_acc = results_one\n",
    "two_train_loss, two_valid_loss, two_train_acc, two_valid_acc = results_two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DCYGcy_CoKQM"
   },
   "outputs": [],
   "source": [
    "### ========== TODO : START ========== ###\n",
    "### part i: generate a plot to comare one_train_loss, one_valid_loss, two_train_loss, two_valid_loss\n",
    "\n",
    "\n",
    "### ========== TODO : END ========== ###\n",
    "\n",
    "### ========== TODO : START ========== ###\n",
    "### part j: generate a plot to comare one_train_acc, one_valid_acc, two_train_acc, two_valid_acc\n",
    "\n",
    "\n",
    "### ========== TODO : END ========== ##\n",
    "\n",
    "### ========== TODO : START ========== ###\n",
    "### part k: calculate the test accuracy\n",
    "\n",
    "\n",
    "### ========== TODO : END ========== ###\n",
    "\n",
    "### ========== TODO : START ========== ###\n",
    "### part l: replace the SGD optimizer with the Adam optimizer and do the experiments again\n",
    "### ========== TODO : END ========== ###\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}