{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-CG6RKO2Rt-Y"
      },
      "outputs": [],
      "source": [
        "# Mount your own google drive to Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "import sys\n",
        "# TODO: Change the path below to the path where your folder locates\n",
        "sys.path.append('/content/gdrive/MyDrive/PS2')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Author      : Yi-Chieh Wu, Sriram Sankararaman\n",
        "\"\"\"\n",
        "\n",
        "# This code was adapted from course material by Jenna Wiens (UMichigan).\n",
        "\n",
        "# python libraries\n",
        "import os\n",
        "import time\n",
        "\n",
        "# numpy libraries\n",
        "import numpy as np\n",
        "\n",
        "# matplotlib libraries\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "0ly5VIYrSV3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "######################################################################\n",
        "# classes\n",
        "######################################################################\n",
        "\n",
        "class Data :\n",
        "\n",
        "    def __init__(self, X=None, y=None) :\n",
        "        \"\"\"\n",
        "        Data class.\n",
        "\n",
        "        Attributes\n",
        "        --------------------\n",
        "            X       -- numpy array of shape (n,d), features\n",
        "            y       -- numpy array of shape (n,), targets\n",
        "        \"\"\"\n",
        "\n",
        "        # n = number of examples, d = dimensionality\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def load(self, filename) :\n",
        "        \"\"\"\n",
        "        Load csv file into X array of features and y array of labels.\n",
        "\n",
        "        Parameters\n",
        "        --------------------\n",
        "            filename -- string, filename\n",
        "        \"\"\"\n",
        "\n",
        "        # load data\n",
        "        with open(filename, 'r') as fid :\n",
        "            data = np.loadtxt(fid, delimiter=\",\")\n",
        "\n",
        "        # separate features and labels\n",
        "        self.X = data[:,:-1]\n",
        "        self.y = data[:,-1]\n",
        "\n",
        "    def plot(self, **kwargs) :\n",
        "        \"\"\"Plot data.\"\"\"\n",
        "\n",
        "        if 'color' not in kwargs :\n",
        "            kwargs['color'] = 'b'\n",
        "\n",
        "        plt.scatter(self.X, self.y, **kwargs)\n",
        "        plt.xlabel('x', fontsize = 16)\n",
        "        plt.ylabel('y', fontsize = 16)\n",
        "        plt.show()\n",
        "\n",
        "# wrapper functions around Data class\n",
        "def load_data(filename) :\n",
        "    data = Data()\n",
        "    data.load(filename)\n",
        "    return data\n",
        "\n",
        "def plot_data(X, y, **kwargs) :\n",
        "    data = Data(X, y)\n",
        "    data.plot(**kwargs)"
      ],
      "metadata": {
        "id": "WvJs1ykbSbZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PolynomialRegression() :\n",
        "\n",
        "    def __init__(self, m=1) :\n",
        "        \"\"\"\n",
        "        Ordinary least squares regression.\n",
        "\n",
        "        Attributes\n",
        "        --------------------\n",
        "            coef_   -- numpy array of shape (d,)\n",
        "                       estimated coefficients for the linear regression problem\n",
        "            m_      -- integer\n",
        "                       order for polynomial regression\n",
        "        \"\"\"\n",
        "        self.coef_ = None\n",
        "        self.m_ = m\n",
        "\n",
        "\n",
        "    def generate_polynomial_features(self, X) :\n",
        "        \"\"\"\n",
        "        Maps X to an mth degree feature vector e.g. [1, X, X^2, ..., X^m].\n",
        "\n",
        "        Parameters\n",
        "        --------------------\n",
        "            X       -- numpy array of shape (n,1), features\n",
        "\n",
        "        Returns\n",
        "        --------------------\n",
        "            Phi     -- numpy array of shape (n,(m+1)), mapped features\n",
        "        \"\"\"\n",
        "\n",
        "        n,d = X.shape\n",
        "\n",
        "        ### ========== TODO : START ========== ###\n",
        "        # part b: modify to create matrix for simple linear model\n",
        "        # part g: modify to create matrix for polynomial model\n",
        "        Phi = X\n",
        "        m = self.m_\n",
        "\n",
        "        ### ========== TODO : END ========== ###\n",
        "\n",
        "        return Phi\n",
        "\n",
        "\n",
        "    def fit_GD(self, X, y, eta=0.01,\n",
        "                eps=0, tmax=10000, verbose=False) :\n",
        "        \"\"\"\n",
        "        Finds the coefficients of a {d-1}^th degree polynomial\n",
        "        that fits the data using least squares batch gradient descent.\n",
        "\n",
        "        Parameters\n",
        "        --------------------\n",
        "            X       -- numpy array of shape (n,d), features\n",
        "            y       -- numpy array of shape (n,), targets\n",
        "            eta     -- float, step size\n",
        "            eps     -- float, convergence criterion\n",
        "            tmax    -- integer, maximum number of iterations\n",
        "            verbose -- boolean, for debugging purposes\n",
        "\n",
        "        Returns\n",
        "        --------------------\n",
        "            self    -- an instance of self\n",
        "        \"\"\"\n",
        "\n",
        "        if verbose :\n",
        "            plt.subplot(1, 2, 2)\n",
        "            plt.xlabel('iteration')\n",
        "            plt.ylabel(r'$J(\\theta)$')\n",
        "            plt.ion()\n",
        "            plt.show()\n",
        "\n",
        "        X = self.generate_polynomial_features(X) # map features\n",
        "        n,d = X.shape\n",
        "        eta_input = eta\n",
        "        self.coef_ = np.zeros(d)                 # coefficients\n",
        "        err_list  = np.zeros((tmax,1))           # errors per iteration\n",
        "\n",
        "        # GD loop\n",
        "        for t in range(tmax) :\n",
        "            ### ========== TODO : START ========== ###\n",
        "            # part f: update step size\n",
        "            # change the default eta in the function signature to 'eta=None'\n",
        "            # and update the line below to your learning rate function\n",
        "            if eta_input is None :\n",
        "                eta = None # change this line\n",
        "            else :\n",
        "                eta = eta_input\n",
        "            ### ========== TODO : END ========== ###\n",
        "\n",
        "            ### ========== TODO : START ========== ###\n",
        "            # part d: update theta (self.coef_) using one step of GD\n",
        "            # hint: you can write simultaneously update all theta using vector math\n",
        "\n",
        "            # track error\n",
        "            # hint: you cannot use self.predict(...) to make the predictions\n",
        "            y_pred = y # change this line\n",
        "            err_list[t] = np.sum(np.power(y - y_pred, 2)) / float(n)\n",
        "            ### ========== TODO : END ========== ###\n",
        "\n",
        "            # stop?\n",
        "            if t > 0 and abs(err_list[t] - err_list[t-1]) <= eps :\n",
        "                break\n",
        "\n",
        "            # debugging\n",
        "            if verbose :\n",
        "                x = np.reshape(X[:,1], (n,1))\n",
        "                cost = self.cost(x,y)\n",
        "                plt.subplot(1, 2, 1)\n",
        "                plt.cla()\n",
        "                plot_data(x, y)\n",
        "                self.plot_regression()\n",
        "                plt.subplot(1, 2, 2)\n",
        "                plt.plot([t+1], [cost], 'bo')\n",
        "                plt.suptitle('iteration: %d, cost: %f' % (t+1, cost))\n",
        "                plt.draw()\n",
        "                plt.pause(0.05) # pause for 0.05 sec\n",
        "\n",
        "        print('number of iterations: %d'%(t+1))\n",
        "\n",
        "        return self\n",
        "\n",
        "\n",
        "    def fit(self, X, y) :\n",
        "        \"\"\"\n",
        "        Finds the coefficients of a {d-1}^th degree polynomial\n",
        "        that fits the data using the closed form solution.\n",
        "\n",
        "        Parameters\n",
        "        --------------------\n",
        "            X       -- numpy array of shape (n,d), features\n",
        "            y       -- numpy array of shape (n,), targets\n",
        "\n",
        "        Returns\n",
        "        --------------------\n",
        "            self    -- an instance of self\n",
        "        \"\"\"\n",
        "\n",
        "        X = self.generate_polynomial_features(X) # map features\n",
        "\n",
        "        ### ========== TODO : START ========== ###\n",
        "        # part e: implement closed-form solution\n",
        "        # hint: use np.dot(...) and np.linalg.pinv(...)\n",
        "        #       be sure to update self.coef_ with your solution\n",
        "\n",
        "        ### ========== TODO : END ========== ###\n",
        "\n",
        "\n",
        "    def predict(self, X) :\n",
        "        \"\"\"\n",
        "        Predict output for X.\n",
        "\n",
        "        Parameters\n",
        "        --------------------\n",
        "            X       -- numpy array of shape (n,d), features\n",
        "\n",
        "        Returns\n",
        "        --------------------\n",
        "            y       -- numpy array of shape (n,), predictions\n",
        "        \"\"\"\n",
        "        if self.coef_ is None :\n",
        "            raise Exception(\"Model not initialized. Perform a fit first.\")\n",
        "\n",
        "        X = self.generate_polynomial_features(X) # map features\n",
        "\n",
        "        ### ========== TODO : START ========== ###\n",
        "        # part c: predict y\n",
        "        y = None\n",
        "        ### ========== TODO : END ========== ###\n",
        "\n",
        "        return y\n",
        "\n",
        "\n",
        "    def cost(self, X, y) :\n",
        "        \"\"\"\n",
        "        Calculates the objective function.\n",
        "\n",
        "        Parameters\n",
        "        --------------------\n",
        "            X       -- numpy array of shape (n,d), features\n",
        "            y       -- numpy array of shape (n,), targets\n",
        "\n",
        "        Returns\n",
        "        --------------------\n",
        "            cost    -- float, objective J(theta)\n",
        "        \"\"\"\n",
        "        ### ========== TODO : START ========== ###\n",
        "        # part d: compute J(theta)\n",
        "        cost = 0\n",
        "        ### ========== TODO : END ========== ###\n",
        "        return cost\n",
        "\n",
        "\n",
        "    def rms_error(self, X, y) :\n",
        "        \"\"\"\n",
        "        Calculates the root mean square error.\n",
        "\n",
        "        Parameters\n",
        "        --------------------\n",
        "            X       -- numpy array of shape (n,d), features\n",
        "            y       -- numpy array of shape (n,), targets\n",
        "\n",
        "        Returns\n",
        "        --------------------\n",
        "            error   -- float, RMSE\n",
        "        \"\"\"\n",
        "        ### ========== TODO : START ========== ###\n",
        "        # part h: compute RMSE\n",
        "        error = 0\n",
        "        ### ========== TODO : END ========== ###\n",
        "        return error\n",
        "\n",
        "\n",
        "    def plot_regression(self, xmin=0, xmax=1, n=50, **kwargs) :\n",
        "        \"\"\"Plot regression line.\"\"\"\n",
        "        if 'color' not in kwargs :\n",
        "            kwargs['color'] = 'r'\n",
        "        if 'linestyle' not in kwargs :\n",
        "            kwargs['linestyle'] = '-'\n",
        "\n",
        "        X = np.reshape(np.linspace(0,1,n), (n,1))\n",
        "        y = self.predict(X)\n",
        "        plot_data(X, y, **kwargs)\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "PIBkAndOSe47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "######################################################################\n",
        "# main\n",
        "######################################################################\n",
        "\n",
        "def main() :\n",
        "    # load data\n",
        "    # TODO: Use the abs path on your own Google Drive\n",
        "    train_data = load_data('/content/gdrive/MyDrive/PS2/regression_train.csv')\n",
        "    test_data = load_data('/content/gdrive/MyDrive/PS2/regression_test.csv')\n",
        "\n",
        "    # print(train_data.X.shape, train_data.y.shape)\n",
        "    # print(test_data.X.shape, test_data.y.shape)\n",
        "\n",
        "\n",
        "    ### ========== TODO : START ========== ###\n",
        "    # part a: main code for visualizations\n",
        "    print('Visualizing data...')\n",
        "\n",
        "    ### ========== TODO : END ========== ###\n",
        "\n",
        "\n",
        "\n",
        "    ### ========== TODO : START ========== ###\n",
        "    # parts b-f: main code for linear regression\n",
        "    print('Investigating linear regression...')\n",
        "\n",
        "    ### ========== TODO : END ========== ###\n",
        "\n",
        "\n",
        "\n",
        "    ### ========== TODO : START ========== ###\n",
        "    # parts g-i: main code for polynomial regression\n",
        "    print('Investigating polynomial regression...')\n",
        "\n",
        "    ### ========== TODO : END ========== ###\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    print(\"Done!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "aTzMRnBRSjuk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ep1yz4g1NCZ_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}